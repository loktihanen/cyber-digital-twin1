# ======================== üì¶ IMPORTS ========================
import streamlit as st
from py2neo import Graph
from PIL import Image
import os
# ======================== ‚öôÔ∏è CONFIGURATION ========================
st.set_page_config(page_title="Cyber Digital Twin Dashboard", layout="wide")
st.title("üß† Cyber Digital Twin ‚Äì Menu principal")

# ======================== üîê CONNEXION NEO4J ========================
@st.cache_resource
def connect_neo4j():
    try:
        uri = "neo4j+s://8d5fbce8.databases.neo4j.io"
        user = "neo4j"
        password = "VpzGP3RDVB7AtQ1vfrQljYUgxw4VBzy0tUItWeRB9CM"
        graph = Graph(uri, auth=(user, password))
        graph.run("RETURN 1").evaluate()
        st.success("‚úÖ Connexion Neo4j Aura r√©ussie")
        return graph
    except Exception as e:
        st.error(f"‚ùå Erreur de connexion Neo4j : {e}")
        st.stop()

graph_db = connect_neo4j()

# ======================== üß≠ MENU PRINCIPAL ========================
st.sidebar.title("üóÇÔ∏è Navigation")

menu_choice = st.sidebar.radio(
    "Acc√®s rapide aux modules :",
    [
        "üìå CSKG1 ‚Äì NVD (vuln√©rabilit√©s publiques)",
        "üß© CSKG2 ‚Äì Nessus (scans internes)",
        "üîÄ CSKG3 ‚Äì Fusion NVD + Nessus",
        "üîÆ Embeddings & RotatE Prediction",
        "üìà R-GCN & Relation Prediction",
        "üß™ Simulation & Digital Twin"
    ]
)

# ======================== üéØ ROUTAGE DES MODULES ========================
st.markdown("---")

if menu_choice == "üìå CSKG1 ‚Äì NVD (vuln√©rabilit√©s publiques)":
    st.header("üìå CSKG1 ‚Äì Graphe bas√© sur la NVD")
    st.info("Ce module affiche les vuln√©rabilit√©s extraites depuis la National Vulnerability Database (CVE, CWE, CPE).")

    st.sidebar.subheader("üéõÔ∏è Filtres sp√©cifiques √† KG1")
    min_cvss = st.sidebar.slider("Score CVSS minimum", 0.0, 10.0, 0.0)
    selected_entities = st.sidebar.multiselect("Entit√©s √† afficher", ["CVE", "CWE", "CPE", "Entity"], default=["CVE", "CWE", "CPE"])

    @st.cache_data
    def load_kg1_data(min_cvss):
        query = f"""
        MATCH (c:CVE)-[r]->(x)
        WHERE c.cvss_score >= {min_cvss}
        RETURN c.name AS source, type(r) AS relation, x.name AS target, labels(x)[0] AS target_type
        """
        return graph_db.run(query).to_data_frame()

    df = load_kg1_data(min_cvss)

    if df.empty:
        st.warning("Aucune relation NVD trouv√©e pour les filtres donn√©s.")
        st.stop()

    import networkx as nx
    from pyvis.network import Network
    import pandas as pd

    st.subheader("üåê Visualisation interactive (`pyvis`)")

    G = nx.DiGraph()
    skipped_rows = 0
    for _, row in df.iterrows():
        src = row.get("source")
        tgt = row.get("target")
        tgt_type = row.get("target_type")

        if not src or not tgt or pd.isna(src) or pd.isna(tgt):
            skipped_rows += 1
            continue

        if tgt_type not in selected_entities:
            continue

        G.add_node(src, type="CVE", label=src)
        G.add_node(tgt, type=tgt_type, label=tgt)
        G.add_edge(src, tgt, label=row["relation"])

    color_map = {
        "CVE": "#ff4d4d", "CWE": "#ffa500", "CPE": "#6699cc", "Entity": "#dddd00"
    }

    net = Network(height="700px", width="100%", bgcolor="#222222", font_color="white")
    for node, data in G.nodes(data=True):
        net.add_node(node, label=data["label"], color=color_map.get(data["type"], "gray"))
    for src, tgt, data in G.edges(data=True):
        net.add_edge(src, tgt, title=data.get("label", ""))

    path = "/tmp/kg1_nvd.html"
    net.save_graph(path)
    with open(path, 'r', encoding='utf-8') as f:
        html = f.read()
    st.components.v1.html(html, height=700, scrolling=True)

    # Statistiques
    st.markdown("### üìä Statistiques du graphe")
    st.markdown(f"- **N≈ìuds** : {G.number_of_nodes()}")
    st.markdown(f"- **Ar√™tes** : {G.number_of_edges()}")
    st.markdown(f"- **Densit√©** : {nx.density(G):.4f}")
    st.markdown(f"- **Lignes ignor√©es** : {skipped_rows}")

    # Table
    st.markdown("### üìÑ Relations extraites")
    st.dataframe(df, use_container_width=True)


elif menu_choice == "üß© CSKG2 ‚Äì Nessus (scans internes)":
    st.header("üß© CSKG2 ‚Äì Graphe bas√© sur les scans Nessus")
    st.info("Ce module permet d'explorer les vuln√©rabilit√©s d√©tect√©es dans ton infrastructure via les r√©sultats Nessus (hosts, plugins, CVE).")

    # üéõÔ∏è Filtres
    st.sidebar.subheader("üéõÔ∏è Filtres sp√©cifiques √† KG2")
    selected_entities = st.sidebar.multiselect(
        "Types d'entit√©s √† afficher",
        ["Host", "Plugin", "CVE", "Service", "Port"],
        default=["Host", "Plugin", "CVE"]
    )
    enable_physics = st.sidebar.toggle("Activer l'animation (physique)", value=True)

    # üì• Chargement des donn√©es
    @st.cache_data
    def load_kg2_data():
        query = """
        MATCH (a)-[r]->(b)
        WHERE labels(a)[0] IN ['Host', 'Plugin'] AND labels(b)[0] IN ['Plugin', 'CVE', 'Port', 'Service']
        RETURN a.name AS source, type(r) AS relation, b.name AS target,
               labels(a)[0] AS source_type, labels(b)[0] AS target_type
        """
        return graph_db.run(query).to_data_frame()

    df = load_kg2_data()

    if df.empty:
        st.warning("Aucune relation Nessus trouv√©e.")
        st.stop()

    import networkx as nx
    from pyvis.network import Network
    import pandas as pd

    st.subheader("üåê Visualisation interactive (`pyvis`)")

    # üìä Construction du graphe
    G = nx.DiGraph()
    skipped = 0
    for _, row in df.iterrows():
        src = row.get("source")
        tgt = row.get("target")
        src_type = row.get("source_type")
        tgt_type = row.get("target_type")

        if not src or not tgt or pd.isna(src) or pd.isna(tgt):
            skipped += 1
            continue

        if src_type not in selected_entities and tgt_type not in selected_entities:
            continue

        G.add_node(src, type=src_type, label=src)
        G.add_node(tgt, type=tgt_type, label=tgt)
        G.add_edge(src, tgt, label=row["relation"])

    color_map = {
        "Host": "#00cc66", "Plugin": "#66ccff", "CVE": "#ff4d4d",
        "Service": "#ffaa00", "Port": "#9966cc"
    }

    # üåê Configuration PyVis
    net = Network(height="700px", width="100%", bgcolor="#1e1e1e", font_color="white")

    if enable_physics:
        net.barnes_hut()
    else:
        net.set_options('''var options = { "physics": { "enabled": false } }''')

    for node, data in G.nodes(data=True):
        net.add_node(node, label=data["label"], color=color_map.get(data["type"], "gray"))
    for src, tgt, data in G.edges(data=True):
        net.add_edge(src, tgt, title=data.get("label", ""))

    path = "/tmp/kg2_nessus.html"
    net.save_graph(path)
    with open(path, 'r', encoding='utf-8') as f:
        html = f.read()
    st.components.v1.html(html, height=700, scrolling=True)

    # üìà Statistiques
    st.markdown("### üìä Statistiques du graphe")
    st.markdown(f"- **N≈ìuds** : {G.number_of_nodes()}")
    st.markdown(f"- **Ar√™tes** : {G.number_of_edges()}")
    st.markdown(f"- **Densit√©** : {nx.density(G):.4f}")
    st.markdown(f"- **Lignes ignor√©es** : {skipped}")

    # üìÑ Table des relations
    st.markdown("### üìÑ Relations extraites")
    st.dataframe(df, use_container_width=True)
elif menu_choice == "üîÄ CSKG3 ‚Äì Fusion NVD + Nessus":
    import networkx as nx
    from pyvis.network import Network
    import tempfile
    import matplotlib.pyplot as plt
    import matplotlib.patches as mpatches

    st.header("üîÄ CSKG3 ‚Äì Graphe fusionn√© & enrichi")
    st.info("Visualisation du graphe r√©sultant de la fusion entre les CVE NVD et Nessus (via SAME_AS ‚Üí CVE_UNIFIED)")

    # === Requ√™te pour le graphe principal ===
    query = """
    MATCH (a)-[r]->(b)
    WHERE a:CVE OR a:CVE_UNIFIED OR a:Plugin OR a:Host OR a:Service
    RETURN a.name AS source, type(r) AS relation, b.name AS target,
           labels(a)[0] AS source_type, labels(b)[0] AS target_type
    LIMIT 300
    """
    data = graph_db.run(query).data()

    # === Construction du graphe NetworkX ===
    G = nx.DiGraph()
    color_map = {
        "CVE": "#ff4d4d",
        "CVE_UNIFIED": "#ffcc00",
        "Plugin": "#66ccff",
        "Host": "#00cc66",
        "Service": "#ffa500"
    }

    skipped = 0
    for row in data:
        src = row.get("source")
        tgt = row.get("target")
        rel = row.get("relation")
        src_type = row.get("source_type")
        tgt_type = row.get("target_type")

        if not src or not tgt:
            skipped += 1
            continue

        G.add_node(src, type=src_type, label=src)
        G.add_node(tgt, type=tgt_type, label=tgt)
        G.add_edge(src, tgt, label=rel)

    # === R√©cup√©ration des statistiques de fusion et alignement ===
    nb_unifies = graph_db.run("""
        MATCH (c:CVE)-[:SAME_AS]-(n:CVE)
        WHERE c.source = 'NVD' AND n.source = 'NESSUS'
        WITH DISTINCT c.name AS cname
        MATCH (u:CVE_UNIFIED {name: cname})
        RETURN count(DISTINCT u) AS nb
    """).evaluate()

    total_fusionnees = graph_db.run("""
        MATCH (c:CVE)-[:SAME_AS]-(n:CVE)
        WHERE c.source = 'NVD' AND n.source = 'NESSUS'
        RETURN count(DISTINCT c) AS total
    """).evaluate()

    same_as_total = graph_db.run("""
        MATCH (:CVE)-[r:SAME_AS]-(:CVE)
        RETURN count(r) AS total
    """).evaluate()

    # === Visualisation PyVis ===
    def draw_pyvis_graph(G):
        net = Network(height="700px", width="100%", bgcolor="#222222", font_color="white")
        for node, data in G.nodes(data=True):
            node_type = data.get("type", "Unknown")
            color = color_map.get(node_type, "lightgray")
            net.add_node(node, label=data.get("label", node), color=color, title=node_type)
        for src, tgt, data in G.edges(data=True):
            net.add_edge(src, tgt, title=data.get("label", ""))
        tmpfile = tempfile.NamedTemporaryFile(delete=False, suffix=".html")
        net.save_graph(tmpfile.name)
        return tmpfile.name

    # === Affichage PyVis
    st.subheader("üåê Visualisation interactive (PyVis)")
    with st.spinner("üîÑ G√©n√©ration du graphe..."):
        html_path = draw_pyvis_graph(G)
        with open(html_path, "r", encoding="utf-8") as f:
            html = f.read()
        st.components.v1.html(html, height=700, scrolling=True)

    # === Visualisation statique matplotlib
    st.subheader("üìä Visualisation statique (matplotlib)")
    node_colors = [color_map.get(G.nodes[n].get("type", "Other"), "#cccccc") for n in G.nodes()]
    pos = nx.spring_layout(G, k=0.3, seed=42)

    plt.figure(figsize=(18, 12))
    nx.draw_networkx_nodes(G, pos, node_size=600, node_color=node_colors)
    nx.draw_networkx_edges(G, pos, edge_color="gray", arrows=True)
    nx.draw_networkx_labels(G, pos, font_size=9)
    edge_labels = nx.get_edge_attributes(G, 'label')
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color="orange", font_size=7)

    legend_patches = [mpatches.Patch(color=c, label=l) for l, c in color_map.items()]
    plt.legend(handles=legend_patches, loc="best", title="Types de n≈ìuds")
    plt.title("üîé Graphe des vuln√©rabilit√©s fusionn√©es (CSKG3)", fontsize=16)
    plt.axis("off")
    st.pyplot(plt)

    # === Statistiques du graphe ===
    st.markdown("### üìà Statistiques CSKG3")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üß† N≈ìuds visibles", G.number_of_nodes())
    with col2:
        st.metric("üîó Relations visibles", G.number_of_edges())
    with col3:
        st.metric("üìä Densit√©", f"{nx.density(G):.4f}")

    st.caption(f"‚ö†Ô∏è Lignes ignor√©es (valeurs nulles) : {skipped}")

    # === Statistiques de fusion ===
    st.markdown("### üß¨ Alignement & Fusion CVE_UNIFIED")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üîÄ Relations SAME_AS", same_as_total)
    with col2:
        st.metric("‚úÖ CVE fusionn√©es", total_fusionnees)
    with col3:
        st.metric("üß¨ CVE_UNIFIED cr√©√©es", nb_unifies)

    # === T√©l√©chargement RDF ===
    st.markdown("---")
    st.subheader("üì§ RDF export√© (Turtle)")
    rdf_file = "kg_fusionne.ttl"
    if os.path.exists(rdf_file):
        with open(rdf_file, "r", encoding="utf-8") as f:
            rdf_content = f.read()
        st.download_button(
            label="üì• T√©l√©charger RDF (kg_fusionne.ttl)",
            data=rdf_content,
            file_name="kg_fusionne.ttl",
            mime="text/turtle"
        )
    else:
        st.warning("‚ö†Ô∏è Le fichier `kg_fusionne.ttl` est introuvable. Ex√©cute `rdf_export.py` ou `propagate_impacts.py`.")


    
#elif menu_choice == "üìà R-GCN & Relation Prediction":
   # st.header("üß† R-GCN ‚Äì Raisonnement sur le graphe de vuln√©rabilit√©s")
   # st.info("Cette section utilise un mod√®le R-GCN pour √©valuer l'impact et la propagation des vuln√©rabilit√©s sur l'infrastructure.")

   # import torch
  #  import torch.nn as nn
#    import torch.optim as optim
    #import numpy as np
   # import pandas as pd
  #  import networkx as nx
  #  import matplotlib.pyplot as plt
   # from sklearn.model_selection import train_test_split

   # device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # ======================== 1. EXTRACTION DES TRIPLES ========================
   # query = """
   # MATCH (s:CVE_UNIFIED)-[r]->(o)
   # WHERE s.name IS NOT NULL AND o.name IS NOT NULL
   # RETURN s.name AS head, type(r) AS relation, o.name AS tail
  #  """
  #  data = graph_db.run(query).to_data_frame().dropna()

  #  all_entities = pd.Index(data['head'].tolist() + data['tail'].tolist()).unique()
 #   all_relations = pd.Index(data['relation']).unique()
  #  entity2id = {e: i for i, e in enumerate(all_entities)}
    #relation2id = {r: i for i, r in enumerate(all_relations)}
    #id2entity = {i: e for e, i in entity2id.items()}
   # id2rel = {i: r for r, i in relation2id.items()}

    #triplets = np.array([(entity2id[h], relation2id[r], entity2id[t]) for h, r, t in data.values])
   # train_triples, test_triples = train_test_split(triplets, test_size=0.1, random_state=42)

    # ======================== 2. MOD√àLE R-GCN ========================
    #class RGCNLayer(nn.Module):
        #def __init__(self, in_dim, out_dim, num_rels):
           # super().__init__()
            #self.weight = nn.Parameter(torch.Tensor(num_rels, in_dim, out_dim))
            #self.self_loop_weight = nn.Parameter(torch.Tensor(in_dim, out_dim))
            #self.bias = nn.Parameter(torch.Tensor(out_dim))
            #nn.init.xavier_uniform_(self.weight)
            #nn.init.xavier_uniform_(self.self_loop_weight)
           # nn.init.zeros_(self.bias)

        #def forward(self, entity_emb, edge_index, edge_type, num_entities):
           # out = torch.zeros_like(entity_emb)
           # for i in range(edge_index.size(1)):
               # src = edge_index[0, i]
               # dst = edge_index[1, i]
               # rel = edge_type[i]
            #    out[dst] += torch.matmul(entity_emb[src], self.weight[rel])
           # out += torch.matmul(entity_emb, self.self_loop_weight)
            #out += self.bias
          #  return torch.relu(out)

    #class RGCN(nn.Module):
       # def __init__(self, num_entities, num_relations, emb_dim=128, num_layers=2):
            #super().__init__()
           # self.emb_dim = emb_dim
           # self.entity_emb = nn.Embedding(num_entities, emb_dim)
          #  self.layers = nn.ModuleList([
              #  RGCNLayer(emb_dim, emb_dim, num_relations) for _ in range(num_layers)
           # ])
          #  self.score_fn = lambda h, t: -torch.norm(h - t, p=1, dim=1)

     #   def forward(self, edge_index, edge_type):
          #  x = self.entity_emb.weight
            #for layer in self.layers:
               # x = layer(x, edge_index, edge_type, x.size(0))
          #  return x

        #def score(self, entity_emb, head_idx, tail_idx):
           # h = entity_emb[head_idx]
        #    t = entity_emb[tail_idx]
         #   return self.score_fn(h, t)

    # ======================== 3. ENTRA√éNEMENT ========================
    #edge_index = torch.tensor([[h, t] for h, r, t in train_triples], dtype=torch.long).t()
    #edge_type = torch.tensor([r for h, r, t in train_triples], dtype=torch.long)

   # model = RGCN(len(entity2id), len(relation2id)).to(device)
   # optimizer = optim.Adam(model.parameters(), lr=1e-3)
  #  loss_fn = nn.MarginRankingLoss(margin=1.0)

    #EPOCHS = 2
    #for epoch in range(EPOCHS):
       # model.train()
       # optimizer.zero_grad()
      #  entity_emb = model(edge_index.to(device), edge_type.to(device))
        #idx = np.random.choice(len(train_triples), 512)
       # batch = train_triples[idx]
        #heads = torch.tensor(batch[:, 0]).to(device)
       # tails = torch.tensor(batch[:, 2]).to(device)
      #  tails_neg = torch.randint(0, len(entity2id), (len(batch),)).to(device)
        #pos_scores = model.score(entity_emb, heads, tails)
       # neg_scores = model.score(entity_emb, heads, tails_neg)
      #  y = torch.ones_like(pos_scores)
       # loss = loss_fn(pos_scores, neg_scores, y)
       # loss.backward()
      #  optimizer.step()
      #  st.write(f"üìâ Epoch {epoch+1}/{EPOCHS} - Loss: {loss.item():.4f}")

    # ======================== 4. √âVALUATION ========================
    #def evaluate_rgcn(entity_emb, test_triples, k=10):
       # ranks = []
      #  hits = 0
      #  for h, r, t in test_triples:
           # scores = model.score(entity_emb, torch.tensor([h]*len(entity_emb)).to(device), torch.arange(len(entity_emb)).to(device))
          #  _, indices = torch.sort(scores, descending=True)
           # rank = (indices == t).nonzero(as_tuple=False).item() + 1
          #  ranks.append(rank)
          #  if rank <= k:
          #      hits += 1
      #  mrr = np.mean([1.0 / r for r in ranks])
       # st.success(f"üìä √âvaluation R-GCN: MRR = {mrr:.4f}, Hits@{k} = {hits/len(test_triples):.4f}")

   # model.eval()
    #entity_emb = model(edge_index.to(device), edge_type.to(device))
    #evaluate_rgcn(entity_emb, test_triples)

    # ======================== 5. SCORING DES H√îTES ========================
    #def compute_host_vuln_scores(hosts, impact_rel_id, entity2id, entity_emb):
      #  scores = {}
        #for host in hosts:
           # if host not in entity2id:
            #    continue
            #host_id = entity2id[host]
           # cves = [e for e in entity2id if "CVE" in e]
           # cve_ids = [entity2id[c] for c in cves]
        #    h_tensor = torch.tensor([host_id]*len(cve_ids)).to(device)
          #  c_tensor = torch.tensor(cve_ids).to(device)
          #  with torch.no_grad():
          #      s = model.score(entity_emb, c_tensor, h_tensor).cpu().numpy().sum()
          #  scores[host] = s
        #return dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))

   # st.subheader("üîé Top 10 h√¥tes vuln√©rables (R-GCN)")
    #hosts = [e for e in entity2id if "Host" in e or "Windows" in e]
   # impact_rel_id = relation2id.get("IMPACTS", 0)
   # scores = compute_host_vuln_scores(hosts, impact_rel_id, entity2id, entity_emb)
   # df_scores = pd.DataFrame(list(scores.items())[:10], columns=["Host", "Score"])
   # st.dataframe(df_scores)

    # ======================== 6. PROPAGATION VISUELLE ========================
   # def build_graph(triplets, id2e, id2r):
     #   G = nx.DiGraph()
      #  for h, r, t in triplets:
          #  G.add_edge(id2e[h], id2e[t], label=id2r[r])
      #  return G

    #def propagate(G, init_scores, max_steps=3, decay=0.6):
      #  propagated = dict(init_scores)
      #  frontier = list(init_scores.keys())
     #   for _ in range(max_steps):
          #  new_frontier = []
           # for node in frontier:
             #   for neigh in G.successors(node):
               #     score = propagated[node] * decay
              #      if score > propagated.get(neigh, 0):
                #        propagated[neigh] = score
                  #      new_frontier.append(neigh)
         #   frontier = new_frontier
      #  return propagated

  #  G_nx = build_graph(train_triples, id2entity, id2rel)
   # propagated = propagate(G_nx, scores)

 #   top20 = sorted(propagated.items(), key=lambda x: x[1], reverse=True)[:20]
#    st.subheader("üìà Propagation de vuln√©rabilit√©")
 #   plt.figure(figsize=(12, 6))
 #   plt.barh([n for n, _ in top20], [s for _, s in top20], color='darkred')
 #   plt.xlabel("Score propag√© (R-GCN)")
    #plt.title("Top 20 entit√©s impact√©es (apr√®s propagation)")
   # plt.gca().invert_yaxis()
   # st.pyplot(plt.gcf())

elif menu_choice == "üß™ Simulation & Digital Twin":
    st.header("üß™ Simulation avec le Jumeau Num√©rique")
    st.info("Ce module permet de simuler des sc√©narios cyber √† l'aide du graphe fusionn√© enrichi CVE_UNIFIED et des h√¥tes r√©els.")

    import networkx as nx
    import matplotlib.pyplot as plt
    import pandas as pd

    # ======================== 1. EXTRACTION DU GRAPHE FUSIONN√â ========================
    @st.cache_data
    def load_simulation_graph():
        query = """
        MATCH (h:Host)-[r:IMPACTS]->(s:Service)
        RETURN h.name AS host, s.name AS service, r.weight AS weight
        """
        return graph_db.run(query).to_data_frame()

    df = load_simulation_graph()

    if df.empty:
        st.warning("Aucune relation IMPACTS d√©tect√©e. Lance d'abord la fusion et la propagation.")
        st.stop()

    # ======================== 2. CONSTRUCTION DU GRAPHE ========================
    G = nx.DiGraph()
    for _, row in df.iterrows():
        host = row["host"]
        service = row["service"]
        weight = row.get("weight", 1.0)
        G.add_edge(host, service, weight=weight)

    st.markdown("### üåê Vue du graphe Host ‚Üí Service")
    pos = nx.spring_layout(G, seed=42)
    plt.figure(figsize=(10, 6))
    nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=1500, font_size=9)
    edge_labels = nx.get_edge_attributes(G, 'weight')
    nx.draw_networkx_edge_labels(G, pos, edge_labels={k: f"{v:.2f}" for k, v in edge_labels.items()}, font_color='red')
    st.pyplot(plt.gcf())

    # ======================== 3. SC√âNARIO DE SIMULATION ========================
    st.subheader("üß™ Simulation What-If")
    selected_host = st.selectbox("Choisir un h√¥te √† simuler", list(G.nodes))
    max_steps = st.slider("Nombre d'√©tapes de propagation", 1, 5, 2)
    decay = st.slider("Facteur de dissipation", 0.1, 1.0, 0.6)

    def simulate_propagation(G, start_node, decay, max_steps):
        scores = {start_node: 1.0}
        frontier = [start_node]
        for _ in range(max_steps):
            next_frontier = []
            for node in frontier:
                for neighbor in G.successors(node):
                    edge_weight = G[node][neighbor].get('weight', 1.0)
                    propagated_score = scores[node] * decay * edge_weight
                    if propagated_score > scores.get(neighbor, 0):
                        scores[neighbor] = propagated_score
                        next_frontier.append(neighbor)
            frontier = next_frontier
        return dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))

    if st.button("üöÄ Lancer la simulation"):
        results = simulate_propagation(G, selected_host, decay, max_steps)

        st.markdown("### üìä R√©sultats de la simulation")
        df_results = pd.DataFrame(list(results.items()), columns=["Noeud", "Score de propagation"])
        st.dataframe(df_results)

        # ======================== 4. ANALYSE DE RISQUE ========================
        st.subheader("üßØ Analyse du risque cumul√© (pond√©r√©)")
        total_risk = sum(results.values())
        st.metric("üìõ Risque total estim√©", f"{total_risk:.2f}")

        # Bar chart
        top_targets = list(results.keys())[:10]
        plt.figure(figsize=(10, 5))
        plt.barh(top_targets[::-1], [results[n] for n in top_targets[::-1]], color='crimson')
        plt.xlabel("Score pond√©r√© (propagation * CVSS)")
        plt.title(f"Top 10 entit√©s impact√©es depuis {selected_host}")
        plt.gca().invert_yaxis()
        st.pyplot(plt.gcf())

# ======================== üß† INFOS DE FIN ========================
st.sidebar.markdown("---")
st.sidebar.info("üéì Projet de M2 ‚Äì Cyber Digital Twin\nUniversit√© Lyon 2 ‚Äì ERIC\nEncadr√© par l‚Äô√©quipe de recherche KG & Cybers√©curit√©")



