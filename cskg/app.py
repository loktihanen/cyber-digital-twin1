# ======================== üì¶ IMPORTS ========================
import streamlit as st
from py2neo import Graph
from PIL import Image
import os
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# ======================== ‚öôÔ∏è CONFIGURATION ========================
st.set_page_config(page_title="Cyber Digital Twin Dashboard", layout="wide")
st.title("üß† Cyber Digital Twin ‚Äì Menu principal")

# ======================== üîê CONNEXION NEO4J ========================
@st.cache_resource
def connect_neo4j():
    try:
        uri = "neo4j+s://8d5fbce8.databases.neo4j.io"
        user = "neo4j"
        password = "VpzGP3RDVB7AtQ1vfrQljYUgxw4VBzy0tUItWeRB9CM"
        graph = Graph(uri, auth=(user, password))
        graph.run("RETURN 1").evaluate()
        st.success("‚úÖ Connexion Neo4j Aura r√©ussie")
        return graph
    except Exception as e:
        st.error(f"‚ùå Erreur de connexion Neo4j : {e}")
        st.stop()

graph_db = connect_neo4j()

# ======================== üß≠ MENU PRINCIPAL ========================
st.sidebar.title("üóÇÔ∏è Navigation")

menu_choice = st.sidebar.radio(
    "Acc√®s rapide aux modules :",
    [
        "üìå CSKG1 ‚Äì NVD (vuln√©rabilit√©s publiques)",
        "üß© CSKG2 ‚Äì Nessus (scans internes)",
        "üîÄ CSKG3 ‚Äì Fusion NVD + Nessus",
        "üîÆ Embeddings & RotatE Prediction",
        "üìà R-GCN & Relation Prediction",
        "üß™ Simulation & Digital Twin",
        "üìä Simulation Heatmap",
        "üß™ Simulation & DTwin2"
    ]
)

# ======================== üéØ ROUTAGE DES MODULES ========================
st.markdown("---")

if menu_choice == "üìå CSKG1 ‚Äì NVD (vuln√©rabilit√©s publiques)":
    st.header("üìå CSKG1 ‚Äì Graphe bas√© sur la NVD")
    st.info("Ce module affiche les vuln√©rabilit√©s extraites depuis la National Vulnerability Database (CVE, CWE, CPE).")

    st.sidebar.subheader("üéõÔ∏è Filtres sp√©cifiques √† KG1")
    min_cvss = st.sidebar.slider("Score CVSS minimum", 0.0, 10.0, 0.0)
    selected_entities = st.sidebar.multiselect("Entit√©s √† afficher", ["CVE", "CWE", "CPE", "Entity"], default=["CVE", "CWE", "CPE"])

    @st.cache_data
    def load_kg1_data(min_cvss):
        query = f"""
        MATCH (c:CVE)-[r]->(x)
        WHERE c.cvss_score >= {min_cvss}
        RETURN c.name AS source, type(r) AS relation, x.name AS target, labels(x)[0] AS target_type
        """
        return graph_db.run(query).to_data_frame()

    df = load_kg1_data(min_cvss)

    if df.empty:
        st.warning("Aucune relation NVD trouv√©e pour les filtres donn√©s.")
        st.stop()

    import networkx as nx
    from pyvis.network import Network
    import pandas as pd

    st.subheader("üåê Visualisation interactive (`pyvis`)")

    G = nx.DiGraph()
    skipped_rows = 0
    for _, row in df.iterrows():
        src = row.get("source")
        tgt = row.get("target")
        tgt_type = row.get("target_type")

        if not src or not tgt or pd.isna(src) or pd.isna(tgt):
            skipped_rows += 1
            continue

        if tgt_type not in selected_entities:
            continue

        G.add_node(src, type="CVE", label=src)
        G.add_node(tgt, type=tgt_type, label=tgt)
        G.add_edge(src, tgt, label=row["relation"])

    color_map = {
        "CVE": "#ff4d4d", "CWE": "#ffa500", "CPE": "#6699cc", "Entity": "#dddd00"
    }

    net = Network(height="700px", width="100%", bgcolor="#222222", font_color="white")
    for node, data in G.nodes(data=True):
        net.add_node(node, label=data["label"], color=color_map.get(data["type"], "gray"))
    for src, tgt, data in G.edges(data=True):
        net.add_edge(src, tgt, title=data.get("label", ""))

    path = "/tmp/kg1_nvd.html"
    net.save_graph(path)
    with open(path, 'r', encoding='utf-8') as f:
        html = f.read()
    st.components.v1.html(html, height=700, scrolling=True)

    # Statistiques
    st.markdown("### üìä Statistiques du graphe")
    st.markdown(f"- **N≈ìuds** : {G.number_of_nodes()}")
    st.markdown(f"- **Ar√™tes** : {G.number_of_edges()}")
    st.markdown(f"- **Densit√©** : {nx.density(G):.4f}")
    st.markdown(f"- **Lignes ignor√©es** : {skipped_rows}")

    # Table
    st.markdown("### üìÑ Relations extraites")
    st.dataframe(df, use_container_width=True)


elif menu_choice == "üß© CSKG2 ‚Äì Nessus (scans internes)":
    st.header("üß© CSKG2 ‚Äì Graphe bas√© sur les scans Nessus")
    st.info("Ce module permet d'explorer les vuln√©rabilit√©s d√©tect√©es dans ton infrastructure via les r√©sultats Nessus (hosts, plugins, CVE).")

    # üéõÔ∏è Filtres
    st.sidebar.subheader("üéõÔ∏è Filtres sp√©cifiques √† KG2")
    selected_entities = st.sidebar.multiselect(
        "Types d'entit√©s √† afficher",
        ["Host", "Plugin", "CVE", "Service", "Port"],
        default=["Host", "Plugin", "CVE"]
    )
    enable_physics = st.sidebar.toggle("Activer l'animation (physique)", value=True)

    # üì• Chargement des donn√©es
    @st.cache_data
    def load_kg2_data():
        query = """
        MATCH (a)-[r]->(b)
        WHERE labels(a)[0] IN ['Host', 'Plugin'] AND labels(b)[0] IN ['Plugin', 'CVE', 'Port', 'Service']
        RETURN a.name AS source, type(r) AS relation, b.name AS target,
               labels(a)[0] AS source_type, labels(b)[0] AS target_type
        """
        return graph_db.run(query).to_data_frame()

    df = load_kg2_data()

    if df.empty:
        st.warning("Aucune relation Nessus trouv√©e.")
        st.stop()

    import networkx as nx
    from pyvis.network import Network
    import pandas as pd

    st.subheader("üåê Visualisation interactive (`pyvis`)")

    # üìä Construction du graphe
    G = nx.DiGraph()
    skipped = 0
    for _, row in df.iterrows():
        src = row.get("source")
        tgt = row.get("target")
        src_type = row.get("source_type")
        tgt_type = row.get("target_type")

        if not src or not tgt or pd.isna(src) or pd.isna(tgt):
            skipped += 1
            continue

        if src_type not in selected_entities and tgt_type not in selected_entities:
            continue

        G.add_node(src, type=src_type, label=src)
        G.add_node(tgt, type=tgt_type, label=tgt)
        G.add_edge(src, tgt, label=row["relation"])

    color_map = {
        "Host": "#00cc66", "Plugin": "#66ccff", "CVE": "#ff4d4d",
        "Service": "#ffaa00", "Port": "#9966cc"
    }

    # üåê Configuration PyVis
    net = Network(height="700px", width="100%", bgcolor="#1e1e1e", font_color="white")

    if enable_physics:
        net.barnes_hut()
    else:
        net.set_options('''var options = { "physics": { "enabled": false } }''')

    for node, data in G.nodes(data=True):
        net.add_node(node, label=data["label"], color=color_map.get(data["type"], "gray"))
    for src, tgt, data in G.edges(data=True):
        net.add_edge(src, tgt, title=data.get("label", ""))

    path = "/tmp/kg2_nessus.html"
    net.save_graph(path)
    with open(path, 'r', encoding='utf-8') as f:
        html = f.read()
    st.components.v1.html(html, height=700, scrolling=True)

    # üìà Statistiques
    st.markdown("### üìä Statistiques du graphe")
    st.markdown(f"- **N≈ìuds** : {G.number_of_nodes()}")
    st.markdown(f"- **Ar√™tes** : {G.number_of_edges()}")
    st.markdown(f"- **Densit√©** : {nx.density(G):.4f}")
    st.markdown(f"- **Lignes ignor√©es** : {skipped}")

    # üìÑ Table des relations
    st.markdown("### üìÑ Relations extraites")
    st.dataframe(df, use_container_width=True)
elif menu_choice == "üîÄ CSKG3 ‚Äì Fusion NVD + Nessus":
    import networkx as nx
    from pyvis.network import Network
    import tempfile
    import os

    st.header("üîÄ CSKG3 ‚Äì Graphe fusionn√© & enrichi")
    st.info("Visualisation du graphe r√©sultant de la fusion entre les CVE NVD et Nessus (via SAME_AS ‚Üí CVE_UNIFIED)")

    # === Requ√™te pour le graphe principal ===
    query = """
    MATCH (a)-[r]->(b)
    WHERE a:CVE OR a:CVE_UNIFIED OR a:Plugin OR a:Host OR a:Service
    RETURN a.name AS source, type(r) AS relation, b.name AS target,
           labels(a)[0] AS source_type, labels(b)[0] AS target_type
    LIMIT 300
    """
    data = graph_db.run(query).data()

    # === Construction du graphe NetworkX ===
    G = nx.DiGraph()
    color_map = {
        "CVE": "#ff4d4d",
        "CVE_UNIFIED": "#ffcc00",
        "Plugin": "#66ccff",
        "Host": "#00cc66",
        "Service": "#ffa500"
    }

    skipped = 0
    for row in data:
        src = row.get("source")
        tgt = row.get("target")
        rel = row.get("relation")
        src_type = row.get("source_type")
        tgt_type = row.get("target_type")

        if not src or not tgt:
            skipped += 1
            continue

        G.add_node(src, type=src_type, label=src)
        G.add_node(tgt, type=tgt_type, label=tgt)
        G.add_edge(src, tgt, label=rel)

    # === Statistiques de fusion ===
    nb_unifies = graph_db.run("""
        MATCH (c:CVE)-[:SAME_AS]-(n:CVE)
        WHERE c.source = 'NVD' AND n.source = 'NESSUS'
        WITH DISTINCT c.name AS cname
        MATCH (u:CVE_UNIFIED {name: cname})
        RETURN count(DISTINCT u) AS nb
    """).evaluate()

    total_fusionnees = graph_db.run("""
        MATCH (c:CVE)-[:SAME_AS]-(n:CVE)
        WHERE c.source = 'NVD' AND n.source = 'NESSUS'
        RETURN count(DISTINCT c) AS total
    """).evaluate()

    same_as_total = graph_db.run("""
        MATCH (:CVE)-[r:SAME_AS]-(:CVE)
        RETURN count(r) AS total
    """).evaluate()

    # === Visualisation PyVis uniquement (matplotlib supprim√©)
    def draw_pyvis_graph(G):
        net = Network(height="700px", width="100%", bgcolor="#222222", font_color="white")
        for node, data in G.nodes(data=True):
            node_type = data.get("type", "Unknown")
            color = color_map.get(node_type, "lightgray")
            net.add_node(node, label=data.get("label", node), color=color, title=node_type)
        for src, tgt, data in G.edges(data=True):
            net.add_edge(src, tgt, title=data.get("label", ""))
        tmpfile = tempfile.NamedTemporaryFile(delete=False, suffix=".html")
        net.save_graph(tmpfile.name)
        return tmpfile.name

    st.subheader("üåê Visualisation interactive (PyVis)")
    with st.spinner("üîÑ G√©n√©ration du graphe..."):
        html_path = draw_pyvis_graph(G)
        with open(html_path, "r", encoding="utf-8") as f:
            html = f.read()
        st.components.v1.html(html, height=700, scrolling=True)

    # === Statistiques du graphe ===
    st.markdown("### üìà Statistiques CSKG3")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üß† N≈ìuds visibles", G.number_of_nodes())
    with col2:
        st.metric("üîó Relations visibles", G.number_of_edges())
    with col3:
        st.metric("üìä Densit√©", f"{nx.density(G):.4f}")

    st.caption(f"‚ö†Ô∏è Lignes ignor√©es (valeurs nulles) : {skipped}")

    # === Statistiques de fusion ===
    st.markdown("### üß¨ Alignement & Fusion CVE_UNIFIED")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üîÄ Relations SAME_AS", same_as_total)
    with col2:
        st.metric("‚úÖ CVE fusionn√©es", total_fusionnees)
    with col3:
        st.metric("üß¨ CVE_UNIFIED cr√©√©es", nb_unifies)

    # === T√©l√©chargement RDF ===
    st.markdown("---")
    st.subheader("üì§ RDF export√© (Turtle)")
    rdf_file = "kg_fusionne.ttl"
    if os.path.exists(rdf_file):
        with open(rdf_file, "r", encoding="utf-8") as f:
            rdf_content = f.read()
        st.download_button(
            label="üì• T√©l√©charger RDF (kg_fusionne.ttl)",
            data=rdf_content,
            file_name="kg_fusionne.ttl",
            mime="text/turtle"
        )
    else:
        st.warning("‚ö†Ô∏è Le fichier `kg_fusionne.ttl` est introuvable. Ex√©cute `rdf_export.py` ou `propagate_impacts.py`.")


    
#elif menu_choice == "üìà R-GCN & Relation Prediction":
   # st.header("üß† R-GCN ‚Äì Raisonnement sur le graphe de vuln√©rabilit√©s")
   # st.info("Cette section utilise un mod√®le R-GCN pour √©valuer l'impact et la propagation des vuln√©rabilit√©s sur l'infrastructure.")

   # import torch
  #  import torch.nn as nn
#    import torch.optim as optim
    #import numpy as np
   # import pandas as pd
  #  import networkx as nx
  #  import matplotlib.pyplot as plt
   # from sklearn.model_selection import train_test_split

   # device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # ======================== 1. EXTRACTION DES TRIPLES ========================
   # query = """
   # MATCH (s:CVE_UNIFIED)-[r]->(o)
   # WHERE s.name IS NOT NULL AND o.name IS NOT NULL
   # RETURN s.name AS head, type(r) AS relation, o.name AS tail
  #  """
  #  data = graph_db.run(query).to_data_frame().dropna()

  #  all_entities = pd.Index(data['head'].tolist() + data['tail'].tolist()).unique()
 #   all_relations = pd.Index(data['relation']).unique()
  #  entity2id = {e: i for i, e in enumerate(all_entities)}
    #relation2id = {r: i for i, r in enumerate(all_relations)}
    #id2entity = {i: e for e, i in entity2id.items()}
   # id2rel = {i: r for r, i in relation2id.items()}

    #triplets = np.array([(entity2id[h], relation2id[r], entity2id[t]) for h, r, t in data.values])
   # train_triples, test_triples = train_test_split(triplets, test_size=0.1, random_state=42)

    # ======================== 2. MOD√àLE R-GCN ========================
    #class RGCNLayer(nn.Module):
        #def __init__(self, in_dim, out_dim, num_rels):
           # super().__init__()
            #self.weight = nn.Parameter(torch.Tensor(num_rels, in_dim, out_dim))
            #self.self_loop_weight = nn.Parameter(torch.Tensor(in_dim, out_dim))
            #self.bias = nn.Parameter(torch.Tensor(out_dim))
            #nn.init.xavier_uniform_(self.weight)
            #nn.init.xavier_uniform_(self.self_loop_weight)
           # nn.init.zeros_(self.bias)

        #def forward(self, entity_emb, edge_index, edge_type, num_entities):
           # out = torch.zeros_like(entity_emb)
           # for i in range(edge_index.size(1)):
               # src = edge_index[0, i]
               # dst = edge_index[1, i]
               # rel = edge_type[i]
            #    out[dst] += torch.matmul(entity_emb[src], self.weight[rel])
           # out += torch.matmul(entity_emb, self.self_loop_weight)
            #out += self.bias
          #  return torch.relu(out)

    #class RGCN(nn.Module):
       # def __init__(self, num_entities, num_relations, emb_dim=128, num_layers=2):
            #super().__init__()
           # self.emb_dim = emb_dim
           # self.entity_emb = nn.Embedding(num_entities, emb_dim)
          #  self.layers = nn.ModuleList([
              #  RGCNLayer(emb_dim, emb_dim, num_relations) for _ in range(num_layers)
           # ])
          #  self.score_fn = lambda h, t: -torch.norm(h - t, p=1, dim=1)

     #   def forward(self, edge_index, edge_type):
          #  x = self.entity_emb.weight
            #for layer in self.layers:
               # x = layer(x, edge_index, edge_type, x.size(0))
          #  return x

        #def score(self, entity_emb, head_idx, tail_idx):
           # h = entity_emb[head_idx]
        #    t = entity_emb[tail_idx]
         #   return self.score_fn(h, t)

    # ======================== 3. ENTRA√éNEMENT ========================
    #edge_index = torch.tensor([[h, t] for h, r, t in train_triples], dtype=torch.long).t()
    #edge_type = torch.tensor([r for h, r, t in train_triples], dtype=torch.long)

   # model = RGCN(len(entity2id), len(relation2id)).to(device)
   # optimizer = optim.Adam(model.parameters(), lr=1e-3)
  #  loss_fn = nn.MarginRankingLoss(margin=1.0)

    #EPOCHS = 2
    #for epoch in range(EPOCHS):
       # model.train()
       # optimizer.zero_grad()
      #  entity_emb = model(edge_index.to(device), edge_type.to(device))
        #idx = np.random.choice(len(train_triples), 512)
       # batch = train_triples[idx]
        #heads = torch.tensor(batch[:, 0]).to(device)
       # tails = torch.tensor(batch[:, 2]).to(device)
      #  tails_neg = torch.randint(0, len(entity2id), (len(batch),)).to(device)
        #pos_scores = model.score(entity_emb, heads, tails)
       # neg_scores = model.score(entity_emb, heads, tails_neg)
      #  y = torch.ones_like(pos_scores)
       # loss = loss_fn(pos_scores, neg_scores, y)
       # loss.backward()
      #  optimizer.step()
      #  st.write(f"üìâ Epoch {epoch+1}/{EPOCHS} - Loss: {loss.item():.4f}")

    # ======================== 4. √âVALUATION ========================
    #def evaluate_rgcn(entity_emb, test_triples, k=10):
       # ranks = []
      #  hits = 0
      #  for h, r, t in test_triples:
           # scores = model.score(entity_emb, torch.tensor([h]*len(entity_emb)).to(device), torch.arange(len(entity_emb)).to(device))
          #  _, indices = torch.sort(scores, descending=True)
           # rank = (indices == t).nonzero(as_tuple=False).item() + 1
          #  ranks.append(rank)
          #  if rank <= k:
          #      hits += 1
      #  mrr = np.mean([1.0 / r for r in ranks])
       # st.success(f"üìä √âvaluation R-GCN: MRR = {mrr:.4f}, Hits@{k} = {hits/len(test_triples):.4f}")

   # model.eval()
    #entity_emb = model(edge_index.to(device), edge_type.to(device))
    #evaluate_rgcn(entity_emb, test_triples)

    # ======================== 5. SCORING DES H√îTES ========================
    #def compute_host_vuln_scores(hosts, impact_rel_id, entity2id, entity_emb):
      #  scores = {}
        #for host in hosts:
           # if host not in entity2id:
            #    continue
            #host_id = entity2id[host]
           # cves = [e for e in entity2id if "CVE" in e]
           # cve_ids = [entity2id[c] for c in cves]
        #    h_tensor = torch.tensor([host_id]*len(cve_ids)).to(device)
          #  c_tensor = torch.tensor(cve_ids).to(device)
          #  with torch.no_grad():
          #      s = model.score(entity_emb, c_tensor, h_tensor).cpu().numpy().sum()
          #  scores[host] = s
        #return dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))

   # st.subheader("üîé Top 10 h√¥tes vuln√©rables (R-GCN)")
    #hosts = [e for e in entity2id if "Host" in e or "Windows" in e]
   # impact_rel_id = relation2id.get("IMPACTS", 0)
   # scores = compute_host_vuln_scores(hosts, impact_rel_id, entity2id, entity_emb)
   # df_scores = pd.DataFrame(list(scores.items())[:10], columns=["Host", "Score"])
   # st.dataframe(df_scores)

    # ======================== 6. PROPAGATION VISUELLE ========================
   # def build_graph(triplets, id2e, id2r):
     #   G = nx.DiGraph()
      #  for h, r, t in triplets:
          #  G.add_edge(id2e[h], id2e[t], label=id2r[r])
      #  return G

    #def propagate(G, init_scores, max_steps=3, decay=0.6):
      #  propagated = dict(init_scores)
      #  frontier = list(init_scores.keys())
     #   for _ in range(max_steps):
          #  new_frontier = []
           # for node in frontier:
             #   for neigh in G.successors(node):
               #     score = propagated[node] * decay
              #      if score > propagated.get(neigh, 0):
                #        propagated[neigh] = score
                  #      new_frontier.append(neigh)
         #   frontier = new_frontier
      #  return propagated

  #  G_nx = build_graph(train_triples, id2entity, id2rel)
   # propagated = propagate(G_nx, scores)

 #   top20 = sorted(propagated.items(), key=lambda x: x[1], reverse=True)[:20]
#    st.subheader("üìà Propagation de vuln√©rabilit√©")
 #   plt.figure(figsize=(12, 6))
 #   plt.barh([n for n, _ in top20], [s for _, s in top20], color='darkred')
 #   plt.xlabel("Score propag√© (R-GCN)")
    #plt.title("Top 20 entit√©s impact√©es (apr√®s propagation)")
   # plt.gca().invert_yaxis()
   # st.pyplot(plt.gcf())

elif menu_choice == "üß™ Simulation & Digital Twin":
    import pandas as pd
    import networkx as nx
    from pyvis.network import Network
    import tempfile

    st.header("üß™ Simulation avec le Jumeau Num√©rique")
    st.info("Ce module permet de simuler des sc√©narios cyber √† l'aide du graphe fusionn√© enrichi CVE_UNIFIED et des h√¥tes r√©els.")

    # === 1. Extraction des relations Host ‚Üí Service avec poids (IMPACTS) ===
    @st.cache_data
    def load_simulation_graph():
        query = """
        MATCH (h:Host)-[r:IMPACTS]->(s:Service)
        RETURN h.name AS host, s.name AS service, r.weight AS weight
        """
        return graph_db.run(query).to_data_frame()

    df = load_simulation_graph()

    if df.empty:
        st.warning("Aucune relation IMPACTS d√©tect√©e. Lance d'abord la fusion et la propagation.")
        st.stop()

    # === 2. Construction du graphe avec NetworkX (et correction des poids) ===
    G = nx.DiGraph()
    for _, row in df.iterrows():
        host = row["host"]
        service = row["service"]
        weight = row.get("weight", 1.0)

        try:
            weight = float(weight)
            label = f"{weight:.2f}"
        except (ValueError, TypeError):
            weight = 1.0
            label = "1.00"

        G.add_node(host, type="Host", label=host, color="#00cc66")
        G.add_node(service, type="Service", label=service, color="#ffaa00")
        G.add_edge(host, service, weight=weight, label=label)

    # === 3. Visualisation interactive PyVis ===
    def draw_pyvis(G):
        net = Network(height="700px", width="100%", bgcolor="#1e1e1e", font_color="white", directed=True)
        for node, data in G.nodes(data=True):
            net.add_node(node, label=data["label"], color=data.get("color", "gray"), title=data.get("type", ""))
        for u, v, data in G.edges(data=True):
            net.add_edge(u, v, value=data.get("weight", 1.0), title=data.get("label", ""))
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".html")
        net.save_graph(tmp.name)
        return tmp.name

    st.subheader("üåê Vue interactive : Host ‚Üí Service")
    with st.spinner("Chargement du graphe..."):
        html_path = draw_pyvis(G)
        with open(html_path, "r", encoding="utf-8") as f:
            html = f.read()
        st.components.v1.html(html, height=700, scrolling=True)

    # === 4. Simulation What-If ===
    st.subheader("üß™ Simulation What-If")
    host_nodes = [n for n, d in G.nodes(data=True) if d.get("type") == "Host"]
    if not host_nodes:
        st.warning("Aucun h√¥te disponible pour la simulation.")
        st.stop()

    selected_host = st.selectbox("Choisir un h√¥te √† simuler", sorted(host_nodes))
    max_steps = st.slider("Nombre d'√©tapes de propagation", 1, 5, 2)
    decay = st.slider("Facteur de dissipation", 0.1, 1.0, 0.6)

    def simulate_propagation(G, start_node, decay, max_steps):
        scores = {start_node: 1.0}
        frontier = [start_node]
        for _ in range(max_steps):
            next_frontier = []
            for node in frontier:
                for neighbor in G.successors(node):
                    edge_weight = G[node][neighbor].get('weight', 1.0)
                    propagated_score = scores[node] * decay * edge_weight
                    if propagated_score > scores.get(neighbor, 0):
                        scores[neighbor] = propagated_score
                        next_frontier.append(neighbor)
            frontier = next_frontier
        return dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))

    if st.button("üöÄ Lancer la simulation"):
        results = simulate_propagation(G, selected_host, decay, max_steps)

        st.markdown("### üìä R√©sultats de la simulation")
        df_results = pd.DataFrame(list(results.items()), columns=["Noeud", "Score de propagation"])
        st.dataframe(df_results, use_container_width=True)

        st.subheader("üßØ Analyse du risque cumul√©")
        total_risk = sum(results.values())
        st.metric("üìõ Risque total estim√©", f"{total_risk:.2f}")
elif menu_choice == "üìä Simulation Heatmap":
    st.header("üìä Heatmap de vuln√©rabilit√© par service")
    st.info("Ce module simule la propagation de CVEs vers les services via les h√¥tes interm√©diaires et g√©n√®re une heatmap de criticit√©.")

    import pandas as pd
    import numpy as np
    import networkx as nx
    import matplotlib.pyplot as plt
    import seaborn as sns
    from pyvis.network import Network
    import streamlit.components.v1 as components
    import tempfile

    # ======================== 1. Requ√™te Neo4j ========================
    @st.cache_data
    def load_cve_to_service():
        query = """
        MATCH (c:CVE_UNIFIED)-[:DETECTED_BY]->(:Plugin)-[:IS_ON]->(h:Host)-[:IMPACTS]->(s:Service)
        RETURN c.name AS cve, h.name AS host, s.name AS service
        """
        return graph_db.run(query).to_data_frame()

    df = load_cve_to_service()

    if df.empty:
        st.warning("‚ö†Ô∏è Aucune correspondance CVE ‚Üí Host ‚Üí Service trouv√©e.")
        st.stop()

    # ======================== 2. Construction du graphe ========================
    G = nx.DiGraph()
    for _, row in df.iterrows():
        cve, host, service = row["cve"], row["host"], row["service"]
        G.add_edge(cve, host, weight=1.0)
        G.add_edge(host, service, weight=1.0)

    cves = sorted(df["cve"].unique())
    services = sorted(df["service"].unique())

    st.markdown("### üéØ S√©lection de CVEs √† simuler")
    selected_cves = st.multiselect("Choisir des CVEs sources", cves[:20], default=cves[:3])
    decay = st.slider("Facteur de dissipation", 0.1, 1.0, 0.7)

    if st.button("üî• G√©n√©rer la heatmap"):
        score_matrix = pd.DataFrame(0, index=selected_cves, columns=services, dtype=float)

        for cve in selected_cves:
            scores = {cve: 1.0}
            frontier = [cve]
            for _ in range(3):
                next_frontier = []
                for node in frontier:
                    for neighbor in G.successors(node):
                        score = scores[node] * decay
                        if score > scores.get(neighbor, 0):
                            scores[neighbor] = score
                            next_frontier.append(neighbor)
                frontier = next_frontier

            for service in services:
                if service in scores:
                    score_matrix.loc[cve, service] = scores[service]

        # ======================== 3. Heatmap ========================
        st.subheader("üå°Ô∏è Heatmap des services vuln√©rables")
        fig, ax = plt.subplots(figsize=(12, 6))
        sns.heatmap(score_matrix, cmap="Reds", linewidths=0.5, annot=True, fmt=".2f", ax=ax)
        ax.set_title("Score de vuln√©rabilit√© CVE ‚Üí Service")
        st.pyplot(fig)

        # ======================== 4. Visualisation PyVis ========================
        st.subheader("üåê Graphe interactif CVE ‚Üí Host ‚Üí Service")
        net = Network(height="600px", width="100%", directed=True)
        for node in G.nodes:
            net.add_node(node, label=node)
        for u, v, d in G.edges(data=True):
            color = "red" if u in selected_cves else "gray"
            net.add_edge(u, v, value=d["weight"], color=color)

        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".html")
        net.show(tmp_file.name)
        with open(tmp_file.name, "r", encoding="utf-8") as f:
            html_content = f.read()
        components.html(html_content, height=650, scrolling=True)
elif menu_choice == "üß™ Simulation & DTwin2":
    st.header("üß™ Simulation avec le Jumeau Num√©rique")
    st.markdown("""
    Ce module s'inscrit dans le cadre de la recherche sur l'utilisation des **graphes de connaissance** 
    et des **jumeaux num√©riques** pour analyser les vuln√©rabilit√©s (CVE_UNIFIED) dans l'organisation.
    """)

    # 1. Extraction des donn√©es pond√©r√©es : CVE ‚Üí Plugin ‚Üí Host ‚Üí Service
    query = """
    MATCH (c:CVE_UNIFIED)<-[:DETECTS]-(:Plugin)<-[:HAS_PLUGIN]-(:Host)-[:RUNS_SERVICE]->(s:Service)
    RETURN c.name AS cve, s.name AS service, c.cvss AS score, c.first_detected AS first_detected, c.last_seen AS last_seen
    """
    df = graph_db.run(query).to_data_frame()

    if df.empty:
        st.error("‚ùå Aucune donn√©e trouv√©e pour CVE_UNIFIED ‚Üí Services")
        st.stop()

    # üéØ Filtrage des services critiques (ex: HTTP, DB)
    services = df["service"].dropna().unique().tolist()
    filtered_services = st.multiselect("üéØ Filtrer les services critiques (ex: HTTP, DB)", options=sorted(services))
    if filtered_services:
        df = df[df["service"].isin(filtered_services)]
        if df.empty:
            st.warning("‚ö†Ô∏è Aucun r√©sultat apr√®s filtrage des services.")
            st.stop()

    # 2. Heatmap Services vs CVE (pond√©r√©e par CVSS)
    pivot_df = df.dropna(subset=["cve", "service", "score"])
    pivot_df = pivot_df.groupby(["service", "cve"]).agg({"score": "sum"}).reset_index()
    heatmap_data = pivot_df.pivot(index="service", columns="cve", values="score").fillna(0)

    st.subheader("üî• Carte d‚Äôimpact des vuln√©rabilit√©s par service (pond√©r√© par CVSS)")
    import matplotlib.pyplot as plt
    import seaborn as sns

    if heatmap_data.empty or heatmap_data.isna().all().all():
        st.warning("‚ö†Ô∏è Donn√©es insuffisantes ou vides pour g√©n√©rer la heatmap.")
    else:
        plt.figure(figsize=(12, 8))
        sns.heatmap(heatmap_data, cmap="Reds", annot=False)
        plt.title("Impact CVE_UNIFIED sur les services ‚Äì Digital Twin")
        st.pyplot(plt.gcf())
        plt.clf()

    # 3. Graphique temporel : √©volution de la criticit√©
    st.subheader("‚è≥ √âvolution temporelle du score de criticit√© (bas√© sur CVE)")
    df_time = df.dropna(subset=["first_detected", "score"])
    df_time["first_detected"] = pd.to_datetime(df_time["first_detected"], errors="coerce")
    df_time = df_time.dropna(subset=["first_detected"])
    df_time = df_time.groupby(pd.Grouper(key="first_detected", freq="M")).agg({"score": "sum"}).reset_index()

    if df_time.empty:
        st.warning("‚ö†Ô∏è Donn√©es temporelles insuffisantes.")
    else:
        plt.figure(figsize=(10, 4))
        plt.plot(df_time["first_detected"], df_time["score"], marker="o", color="blue")
        plt.title("√âvolution mensuelle du score de criticit√© CVSS")
        plt.xlabel("Date de premi√®re d√©tection")
        plt.ylabel("Score cumul√© CVSS")
        st.pyplot(plt.gcf())
        plt.clf()

    # 4. V√©rification SAME_AS (fusion KG1 ‚Üî KG2 via CVE_UNIFIED)
    st.subheader("üîÅ V√©rification des alignements SAME_AS dans le graphe de connaissance")
    query_align = """
    MATCH (c:CVE)-[:SAME_AS]-(n:CVE)-[:SAME_AS]-(u:CVE_UNIFIED)
    RETURN count(DISTINCT u) AS total_aligned
    """
    nb = graph_db.run(query_align).evaluate()
    st.success(f"‚úÖ {nb} CVE_UNIFIED align√©s via SAME_AS entre KG1 (NVD) et KG2 (Nessus)")

# ======================== üß† INFOS DE FIN ========================
st.sidebar.markdown("---")
st.sidebar.info("üéì Projet de M2 ‚Äì Cyber Digital Twin\nUniversit√© Lyon 2 ‚Äì ERIC\nEncadr√© par l‚Äô√©quipe de recherche KG & Cybers√©curit√©")



